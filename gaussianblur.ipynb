{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bfd3c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('data/handwritten_sample1.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.medianBlur(gray, 5)\n",
    "thresh = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,11,8)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "dilate = cv2.dilate(thresh, kernel, iterations=6)\n",
    "cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "for c in cnts:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    ROI = image[y:y+h, x:x+w]\n",
    "    cv2.imwrite('temp/ROI.png', ROI)\n",
    "    break\n",
    "\n",
    "cv2.imshow('thresh', thresh)\n",
    "cv2.imshow('dilate', dilate)\n",
    "cv2.imshow('ROI', ROI)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652132a",
   "metadata": {},
   "source": [
    "Updated code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c391761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "My Nayve ts Saakely Wags,\n",
      "\n",
      " \n",
      "\n",
      "Th is an Open CV baton .\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Optional: Set tesseract path if not in PATH (for Windows users)\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Step 1: Load the image\n",
    "image = cv2.imread('data/intro.jpg')\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"Image not found. Check the path.\")\n",
    "\n",
    "# Step 2: Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "blur = cv2.medianBlur(gray, 5)\n",
    "thresh = cv2.adaptiveThreshold(\n",
    "    blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    cv2.THRESH_BINARY_INV, 11, 8\n",
    ")\n",
    "\n",
    "# Step 4: Find contours to isolate the handwritten region\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "dilate = cv2.dilate(thresh, kernel, iterations=6)\n",
    "\n",
    "contours = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "# # Step 5: Crop the largest region of interest\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    ROI = image[y:y+h, x:x+w]\n",
    "    break  # Only consider the largest contour\n",
    "\n",
    "# Step 6: OCR on the extracted region\n",
    "# Convert ROI to grayscale and threshold again for better OCR\n",
    "roi_gray = cv2.cvtColor(ROI, cv2.COLOR_BGR2GRAY)\n",
    "_, roi_thresh = cv2.threshold(roi_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Run OCR\n",
    "extracted_text = pytesseract.image_to_string(roi_thresh, lang='eng')\n",
    "\n",
    "\n",
    "# Step 7: Show output\n",
    "print(\"Extracted Text:\\n\", extracted_text)\n",
    "\n",
    "# Optional: Visual debug\n",
    "cv2.imshow('Thresholded ROI', roi_thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df03cf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " —_— >\n",
      "1 m\n",
      "\n",
      ">\n",
      "\n",
      "O\n",
      "\n",
      "<= ,\n",
      "©\n",
      "ae\n",
      "om\n",
      "ee\n",
      "ae\n",
      "E65\n",
      "=\n",
      "44 er\n",
      "OS\n",
      "RET\n",
      "Eee\n",
      ". _\n",
      "=\n",
      ".\n",
      "Ba\n",
      "i |\n",
      "es\n",
      "a tee\n",
      "jahea\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "# Optional: Set Tesseract path on Windows\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('data/intro.jpg')\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"Image not found. Check the path.\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Preprocessing\n",
    "blur = cv2.medianBlur(gray, 3)\n",
    "thresh = cv2.adaptiveThreshold(\n",
    "    blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    cv2.THRESH_BINARY_INV, 11, 6\n",
    ")\n",
    "\n",
    "# Dilation to connect components\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 3))\n",
    "dilate = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort contours top-to-bottom, left-to-right\n",
    "def get_contour_precedence(contour, cols):\n",
    "    tolerance_factor = 10\n",
    "    origin = cv2.boundingRect(contour)\n",
    "    return ((origin[1] // tolerance_factor) * tolerance_factor) * cols + origin[0]\n",
    "\n",
    "contours = sorted(contours, key=lambda ctr: get_contour_precedence(ctr, image.shape[1]))\n",
    "\n",
    "# OCR config\n",
    "custom_config = r'--oem 1 --psm 6'\n",
    "\n",
    "# Loop through all contours\n",
    "results = []\n",
    "debug_image = image.copy()\n",
    "\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    if w < 25 or h < 25:\n",
    "        continue  # Skip small noise\n",
    "\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "    roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, roi_thresh = cv2.threshold(roi_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Resize for better OCR\n",
    "    scale = 2\n",
    "    roi_resized = cv2.resize(roi_thresh, (w * scale, h * scale), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # OCR\n",
    "    text = pytesseract.image_to_string(roi_resized, lang='eng', config=custom_config).strip()\n",
    "    if text:\n",
    "        results.append(text)\n",
    "\n",
    "        # Draw rectangle on debug image\n",
    "        cv2.rectangle(debug_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Print and save final extracted text\n",
    "extracted_text = \"\\n\".join(results)\n",
    "print(\"Extracted Text:\\n\", extracted_text)\n",
    "\n",
    "with open(\"output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(extracted_text)\n",
    "\n",
    "# Optional visual debug\n",
    "cv2.imshow('Detected Regions', debug_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
